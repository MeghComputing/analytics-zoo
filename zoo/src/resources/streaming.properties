#Variable Configs

#Variable Log Config
spark.executor.extraJavaOptions=-Dlog4j.configuration=file:/scratch/pgargesa/SPARK_AI/properties/log4j.properties
spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/scratch/pgargesa/SPARK_AI/properties/log4j.properties
spark.eventLog.dir=file:/scratch/pgargesa/SPARK_AI/logs/spark_logs/cpu
spark.history.fs.logDirectory=file:/scratch/pgargesa/SPARK_AI/logs/spark_logs/cpu
checkpoint.location=/scratch/pgargesa/SPARK_AI/logs/checkpoint/cpu

#Variable Output Config
classification.out.file=/scratch/resources/classifications_cpu.sock
fps.out.file=/scratch/resources/fps_cpu.sock

#Variable DL Config
model.full.path=/scratch/pgargesa/SPARK_AI/model/analytics-zoo_resnet-50_imagenet_0.1.0.model
label.file.path=/scratch/pgargesa/SPARK_AI/properties/Labels.txt

#Variable Spark Config
spark.executor.cores=8
spark.streaming.receiver.maxRate=8
rdd.partition=8
spark.streaming.kafka.maxRatePerPartition=1

#Variable Kafka Config - Set to executor/slave ip
bootstrap.servers=222.10.0.60:9092

#Variable Demo Config - monitor and set to =required througput/observed throughput
#monitor and set to =required througput/observed throughput
multiplication.factor=9
#frequency of o/p refresh
maxOffsetsPerTrigger=5

#Fixed Spark properties
spark.shuffle.reduceLocality.enabled=false
spark.shuffle.blockTransferService=nio
spark.scheduler.minRegisteredResourcesRatio=1.0
spark.speculation=true
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.eventLog.enabled=true
spark.driver.maxResultSize=2G
spark.shuffle.memoryFraction=0
spark.network.timeout=10000000
spark.app.name=Image-Streaming-cpu

#Fixed Kafka properties
group.id=consumerGroup-cpu
kafka.topic=imagestream-cpu
max.poll.records=1
enable.auto.commit.config=false
auto.offset.reset=earliest
num.receivers=1

#Fixed Classification pipeline properties
inference.batchsize=4
streaming.batch.duration=1000
inference.mode=distributed
model.name=resnet-50
app.exec.duration=60000
sink.writer=CustomFileWriter

